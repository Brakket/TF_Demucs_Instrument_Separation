{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enabled memory growth on 8 GPU(s)\n"
          ]
        }
      ],
      "source": [
        "# GPU setup (memory growth)\n",
        "import os\n",
        "import tensorflow as tf\n",
        "try:\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f'Enabled memory growth on {len(gpus)} GPU(s)')\n",
        "    else:\n",
        "        print('No GPUs available')\n",
        "except Exception as e:\n",
        "    print('Memory growth setup skipped:', e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and constants\n",
        "import os, math\n",
        "import numpy as np\n",
        "import librosa, soundfile as sf\n",
        "import tensorflow as tf\n",
        "\n",
        "from demucs_v4_model import (\n",
        "    ExpandDims, ReduceMean, LocalSelfAttention, STFT, InverseSTFT, custom_loss\n",
        ")\n",
        "\n",
        "SR = 44100\n",
        "PADDED_LEN = 441_000\n",
        "\n",
        "INSTRUMENT_NAMES = [\n",
        "    'Guitar','Drums','Piano','Bass','Strings (continued)',\n",
        "    'Organ','Synth Lead','Synth Pad','Chromatic Percussion',\n",
        "    'Brass','Pipe','Reed','Strings'\n",
        "]\n",
        "MODEL_KEYS = {name: f'instrument_{i+1}' for i, name in enumerate(INSTRUMENT_NAMES)}\n",
        "KEY_TO_NAME = {v: k for k, v in MODEL_KEYS.items()}\n",
        "\n",
        "def model_chunk_len(m):\n",
        "    s = m.inputs[0].shape\n",
        "    return int(s[1]) if s and s[1] else PADDED_LEN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n",
            "Using MirroredStrategy with 8 GPUs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ListWrapper(['conv1d_155', 'conv1d_173', 'conv1d_175', 'conv1d_177', 'conv1d_179', 'conv1d_157', 'conv1d_159', 'conv1d_161', 'conv1d_163', 'conv1d_165', 'conv1d_167', 'conv1d_169', 'conv1d_171'])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model (single GPU/CPU for robust inference)\n",
        "model = tf.keras.models.load_model(\n",
        "    'demucs_v4_fixed_model.keras',\n",
        "    custom_objects={\n",
        "        'ExpandDims': ExpandDims,\n",
        "        'ReduceMean': ReduceMean,\n",
        "        'LocalSelfAttention': LocalSelfAttention,\n",
        "        'STFT': STFT,\n",
        "        'InverseSTFT': InverseSTFT,\n",
        "        'custom_loss': custom_loss,\n",
        "    },\n",
        "    compile=False,\n",
        ")\n",
        "# Optional: print output names\n",
        "model.output_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overlap-add separation using output keys from first predict (like Testing)\n",
        "def separate_long_audio(model, audio_path, output_dir, sr=SR, batch_size=8):\n",
        "    import os, numpy as np\n",
        "    audio_path = os.path.expanduser(audio_path)\n",
        "    output_dir = os.path.expanduser(output_dir)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load audio\n",
        "    wav, file_sr = sf.read(audio_path, always_2d=False)\n",
        "    if file_sr != sr:\n",
        "        wav = librosa.resample(wav, orig_sr=file_sr, target_sr=sr)\n",
        "    if wav.ndim == 2:\n",
        "        wav = wav.mean(axis=1)\n",
        "    wav = wav.astype(np.float32)\n",
        "\n",
        "    # Model sizes\n",
        "    CHUNK = model_chunk_len(model)\n",
        "    HOP = CHUNK // 2\n",
        "    WIN = np.hanning(CHUNK).astype(np.float32)\n",
        "    N = len(wav)\n",
        "\n",
        "    # Probe first chunk to determine output structure\n",
        "    head = wav[:CHUNK]\n",
        "    peak0 = float(np.max(np.abs(head))) or 1.0\n",
        "    if len(head) < CHUNK:\n",
        "        head = np.pad(head, (0, CHUNK - len(head)))\n",
        "    head_in = (head / peak0).astype(np.float32)[np.newaxis, :, np.newaxis]\n",
        "    test_out = model.predict(head_in, verbose=0)\n",
        "    if isinstance(test_out, dict):\n",
        "        keys = list(test_out.keys())\n",
        "        use_dict = True\n",
        "    else:\n",
        "        keys = list(range(len(test_out)))\n",
        "        use_dict = False\n",
        "\n",
        "    # Accumulators per head\n",
        "    if use_dict:\n",
        "        acc = {k: np.zeros(N + CHUNK, np.float32) for k in keys}\n",
        "    else:\n",
        "        acc = [np.zeros(N + CHUNK, np.float32) for _ in keys]\n",
        "    wsum = np.zeros(N + CHUNK, np.float32)\n",
        "\n",
        "    batch = []\n",
        "    starts = []  # (start_idx, peak)\n",
        "\n",
        "    def flush():\n",
        "        if not batch:\n",
        "            return\n",
        "        xin = np.stack(batch, axis=0)\n",
        "        out = model.predict(xin, verbose=0)\n",
        "        for b, (start, peak) in enumerate(starts):\n",
        "            if use_dict:\n",
        "                for k in keys:\n",
        "                    y = out[k][b, :, 0].astype(np.float32) * peak\n",
        "                    acc[k][start:start+CHUNK] += y * WIN\n",
        "            else:\n",
        "                for i in keys:\n",
        "                    y = out[i][b, :, 0].astype(np.float32) * peak\n",
        "                    acc[i][start:start+CHUNK] += y * WIN\n",
        "            wsum[start:start+CHUNK] += WIN\n",
        "        batch.clear(); starts.clear()\n",
        "\n",
        "    pos = 0\n",
        "    while pos < N:\n",
        "        end = min(pos + CHUNK, N)\n",
        "        x = wav[pos:end]\n",
        "        peak = float(np.max(np.abs(x))) if len(x) else 1.0\n",
        "        if peak < 1e-7: peak = 1.0\n",
        "        if len(x) < CHUNK: x = np.pad(x, (0, CHUNK - len(x)))\n",
        "        xin = (x / peak).astype(np.float32)[..., None]\n",
        "        batch.append(xin); starts.append((pos, peak))\n",
        "        if len(batch) == batch_size: flush()\n",
        "        pos += HOP\n",
        "    flush()\n",
        "\n",
        "    eps = 1e-8\n",
        "    if use_dict:\n",
        "        for k in keys:\n",
        "            acc[k][:N] = acc[k][:N] / np.maximum(wsum[:N], eps)\n",
        "            name = KEY_TO_NAME.get(k, str(k))\n",
        "            sf.write(os.path.join(output_dir, f'{name}.wav'), acc[k][:N].astype(np.float32), sr, subtype='PCM_16')\n",
        "    else:\n",
        "        for i in keys:\n",
        "            y = (acc[i][:N] / np.maximum(wsum[:N], eps)).astype(np.float32)\n",
        "            name = INSTRUMENT_NAMES[i] if i < len(INSTRUMENT_NAMES) else f\"stem_{i+1}\"\n",
        "            sf.write(os.path.join(output_dir, f'{name}.wav'), y, sr, subtype='PCM_16')\n",
        "    print(f\"Saved stems to {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-30 04:29:48.579940: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
            "\t [[RemoteCall]]\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'conv1d_155'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_26604/1452345236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Uncomment to run:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mseparate_long_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUDIO_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_26604/2669666678.py\u001b[0m in \u001b[0;36mseparate_long_audio\u001b[0;34m(model, audio_path, output_dir, sr, batch_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mHOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_26604/2669666678.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpeak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mWIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mwsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mWIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv1d_155'"
          ]
        }
      ],
      "source": [
        "# Run prediction\n",
        "AUDIO_PATH = '~/madari3/1508 mix.wav'\n",
        "OUTPUT_DIR = '~/madari3/output'\n",
        "BATCH_SIZE = 8  # increase to use more GPU memory\n",
        "\n",
        "# Uncomment to run:\n",
        "separate_long_audio(model, AUDIO_PATH, OUTPUT_DIR, batch_size=BATCH_SIZE)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Cloud IDE)",
      "language": "python",
      "name": "cloud-ide"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}