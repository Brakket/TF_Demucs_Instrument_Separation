{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Demucs V4 Model Evaluation\n",
    "\n",
    "This notebook evaluates the trained Hybrid Demucs model on the test set and includes utilities for separating full-length audio files.\n",
    "\n",
    "## Contents\n",
    "1. **Setup** - GPU configuration and imports\n",
    "2. **Data Generator** - Test data loading\n",
    "3. **Model Loading** - Load trained model with custom layers\n",
    "4. **Evaluation** - Compute per-instrument loss on test set\n",
    "5. **Audio Separation** - Separate a full-length audio file into stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUqj0nbcz_lX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 06:44:11.502260: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-29 06:44:11.516511: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761720251.533903  102393 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761720251.539497  102393 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761720251.552808  102393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761720251.552824  102393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761720251.552827  102393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761720251.552828  102393 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-29 06:44:11.556916: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth on – no per-process hard cap.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# GPU Setup and Imports\n",
    "# ==============================================================================\n",
    "\n",
    "import os, random, glob\n",
    "\n",
    "# Configure GPU memory growth before importing TensorFlow\n",
    "os.environ.pop(\"TF_GPU_ALLOCATOR\", None)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable memory growth to avoid allocating all GPU memory upfront\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"Memory growth enabled on {len(gpus)} GPU(s)\")\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Import custom model components\n",
    "from demucs_v4_model import (\n",
    "    demucs_v4_fixed,\n",
    "    ExpandDims,\n",
    "    ReduceMean,\n",
    "    LocalSelfAttention,\n",
    "    STFT,\n",
    "    InverseSTFT,\n",
    "    custom_loss,\n",
    ")\n",
    "\n",
    "# ==============================================================================\n",
    "# Audio Constants and Utilities\n",
    "# ==============================================================================\n",
    "\n",
    "SR            = 44_100      # Sample rate (44.1 kHz)\n",
    "CHUNK_SECS    = 10          # Chunk duration in seconds\n",
    "CHUNK_SAMPLES = 441_000     # 10 seconds * 44100 samples/sec\n",
    "PADDED_LEN    = 441_000     # Model input length\n",
    "\n",
    "\n",
    "def load_mono(fp, sr=SR):\n",
    "    \"\"\"Load audio file as mono float32.\"\"\"\n",
    "    wav, _ = librosa.load(fp, sr=sr, mono=True)\n",
    "    return wav.astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_or_trim(x, tgt_len=PADDED_LEN):\n",
    "    \"\"\"Pad with zeros or trim audio to exact target length.\"\"\"\n",
    "    if len(x) < tgt_len:\n",
    "        return np.pad(x, (0, tgt_len - len(x)))\n",
    "    return x[:tgt_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "Test data generator that yields (mix, stems) batches for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Guitar': 'instrument_1', 'Drums': 'instrument_2', 'Piano': 'instrument_3', 'Bass': 'instrument_4', 'Strings (continued)': 'instrument_5', 'Organ': 'instrument_6', 'Synth Lead': 'instrument_7', 'Synth Pad': 'instrument_8', 'Chromatic Percussion': 'instrument_9', 'Brass': 'instrument_10', 'Pipe': 'instrument_11', 'Reed': 'instrument_12', 'Strings': 'instrument_13'}\n"
     ]
    }
   ],
   "source": [
    "# Target instrument stems (13 total)\n",
    "INSTRUMENT_NAMES = [\n",
    "    \"Guitar\", \"Drums\", \"Piano\", \"Bass\", \"Strings (continued)\",\n",
    "    \"Organ\", \"Synth Lead\", \"Synth Pad\", \"Chromatic Percussion\",\n",
    "    \"Brass\", \"Pipe\", \"Reed\", \"Strings\"\n",
    "]\n",
    "# Map instrument names to model output keys\n",
    "MODEL_KEYS = {n: f\"instrument_{i+1}\" for i, n in enumerate(INSTRUMENT_NAMES)}\n",
    "print(MODEL_KEYS)\n",
    "\n",
    "\n",
    "def data_generator(root, batch_size=8):\n",
    "    \"\"\"\n",
    "    Infinite generator yielding (mix, targets_dict) batches for evaluation.\n",
    "    \n",
    "    Args:\n",
    "        root: Path to directory containing track subdirectories\n",
    "        batch_size: Number of samples per batch\n",
    "    \"\"\"\n",
    "    root = os.path.expanduser(root)\n",
    "    track_dirs = [d for d in glob.glob(os.path.join(root, '*')) if os.path.isdir(d)]\n",
    "    n_tracks = len(track_dirs)\n",
    "    chunk = CHUNK_SAMPLES\n",
    "\n",
    "    while True:\n",
    "        random.shuffle(track_dirs)\n",
    "\n",
    "        for i in range(0, n_tracks, batch_size):\n",
    "            dirs = track_dirs[i:i + batch_size]\n",
    "\n",
    "            mixes   = []\n",
    "            targets = {k: [] for k in MODEL_KEYS.values()}\n",
    "\n",
    "            for d in dirs:\n",
    "                # Load the mix audio file\n",
    "                mix_files = [f for f in os.listdir(d) if 'mix_chunk' in f.lower()]\n",
    "                if not mix_files:\n",
    "                    continue\n",
    "                mix_full = load_mono(os.path.join(d, mix_files[0]))\n",
    "\n",
    "                # random starting offset (if long enough)\n",
    "                if len(mix_full) > chunk:\n",
    "                    start = np.random.randint(0, len(mix_full) - chunk + 1)\n",
    "                    mix_clip = mix_full[start:start + chunk]\n",
    "                else:\n",
    "                    mix_clip = pad_or_trim(mix_full, chunk)\n",
    "\n",
    "                # Peak-normalize for consistent scaling\n",
    "                peak = np.max(np.abs(mix_clip)) + 1e-7\n",
    "                mix_clip /= peak\n",
    "\n",
    "                # Load and normalize each instrument stem\n",
    "                stem_dict = {}\n",
    "                for name in INSTRUMENT_NAMES:\n",
    "                    fmatch = next(\n",
    "                        (f for f in os.listdir(d)\n",
    "                         if name.lower() in f.lower() and '_chunk_' in f.lower()),\n",
    "                        None\n",
    "                    )\n",
    "                    if fmatch:\n",
    "                        full = load_mono(os.path.join(d, fmatch))\n",
    "                        if len(full) > chunk:\n",
    "                            stem = full[start:start + chunk]\n",
    "                        else:\n",
    "                            stem = pad_or_trim(full, chunk)\n",
    "                        stem = stem / peak  # Use same normalization as mix\n",
    "                    else:\n",
    "                        stem = np.zeros(chunk, dtype=np.float32)\n",
    "                    stem_dict[name] = stem\n",
    "\n",
    "                # Ensure exact length for model input\n",
    "                mix_pad = pad_or_trim(mix_clip, PADDED_LEN)\n",
    "                mixes.append(mix_pad)\n",
    "\n",
    "                for name in INSTRUMENT_NAMES:\n",
    "                    targets[MODEL_KEYS[name]].append(\n",
    "                        pad_or_trim(stem_dict[name], PADDED_LEN)[..., None]\n",
    "                    )\n",
    "\n",
    "            if not mixes:\n",
    "                continue  # Skip empty batch\n",
    "\n",
    "            # Convert to numpy arrays with channel dimension\n",
    "            mix_batch = np.array(mixes, dtype=np.float32)[..., None]\n",
    "            tgt_batch = {k: np.array(v, dtype=np.float32) for k, v in targets.items()}\n",
    "\n",
    "            yield mix_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model\n",
    "\n",
    "Load the saved model with custom layer definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fH7SYGNKDbS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761719416.448287   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78761 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:61:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761719416.451082   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78761 MB memory:  -> device: 1, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:62:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761719416.452652   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78761 MB memory:  -> device: 2, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:63:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761719416.454238   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78761 MB memory:  -> device: 3, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:64:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761719416.455772   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 78761 MB memory:  -> device: 4, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6a:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761719416.457316   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 78761 MB memory:  -> device: 5, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6b:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761719416.458778   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 78761 MB memory:  -> device: 6, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6c:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761719416.460297   78469 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 78761 MB memory:  -> device: 7, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6d:00.0, compute capability: 9.0\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_8', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_9', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_12', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_13', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_14', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_15', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# MSE loss function for model compilation\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"Mean Squared Error loss for waveform reconstruction.\"\"\"\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "# Load pre-trained model with custom layer definitions\n",
    "reloaded = tf.keras.models.load_model(\n",
    "    \"demucs_v4_fixed_model.keras\",\n",
    "    custom_objects={\n",
    "        \"ExpandDims\": ExpandDims,\n",
    "        \"ReduceMean\": ReduceMean,\n",
    "        \"LocalSelfAttention\": LocalSelfAttention,\n",
    "        \"STFT\": STFT,\n",
    "        \"InverseSTFT\": InverseSTFT,\n",
    "        \"custom_loss\": custom_loss,\n",
    "    },\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "# Enable mixed precision for faster inference\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the model on the test dataset and report per-instrument loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ScprZkvzb_p",
    "outputId": "640c8985-3159-42a2-cbc5-9d8566e6f3ef"
   },
   "outputs": [],
   "source": [
    "# Evaluation configuration\n",
    "NUM_INST   = 13\n",
    "BATCH_SIZE = 8\n",
    "TEST_STEPS = 3545  # Number of evaluation batches\n",
    "\n",
    "test_dir = '~/madari3/gcs-bucket/Slakh_Dataset_Chunked/test_chunked'\n",
    "\n",
    "# Compile model for evaluation\n",
    "reloaded.compile(optimizer='adam', loss=custom_loss, jit_compile=False, run_eagerly=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made it\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753765925.681847    2716 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753765930.255780    2716 service.cc:152] XLA service 0x767c7c00bf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753765930.255821    2716 service.cc:160]   StreamExecutor device (0): NVIDIA H100 PCIe, Compute Capability 9.0\n",
      "I0000 00:00:1753765931.013276    2716 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 465/3545\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:41:27\u001b[0m 2s/step - instrument_10_loss: nan - instrument_11_loss: nan - instrument_12_loss: nan - instrument_13_loss: nan - instrument_1_loss: nan - instrument_2_loss: nan - instrument_3_loss: nan - instrument_4_loss: nan - instrument_5_loss: nan - instrument_6_loss: nan - instrument_7_loss: nan - instrument_8_loss: nan - instrument_9_loss: nan - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2558/3234434608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgbarLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m results = reloaded.evaluate(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_evaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create test dataset with prefetching\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(test_dir, BATCH_SIZE),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, PADDED_LEN, 1), dtype=tf.float32),\n",
    "        {k: tf.TensorSpec(shape=(None, PADDED_LEN, 1), dtype=tf.float32)\n",
    "         for k in MODEL_KEYS.values()}\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Run evaluation\n",
    "from tensorflow.keras.callbacks import ProgbarLogger\n",
    "results = reloaded.evaluate(\n",
    "    test_ds,\n",
    "    steps=TEST_STEPS,\n",
    "    callbacks=[ProgbarLogger()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nTotal loss: {results[0]:.4f}\")\n",
    "print(\"\\nPer-instrument losses:\")\n",
    "for i in range(1, len(results)):\n",
    "    model_key = f\"instrument_{i}\"\n",
    "    for key in MODEL_KEYS:\n",
    "        if MODEL_KEYS[key] == model_key:\n",
    "            print(f\"  {key}: {results[i]:.4f}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Separation Utility\n",
    "\n",
    "Separate a full-length audio file into individual instrument stems using overlap-add processing for seamless output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezTE0rIc1ygJ",
    "outputId": "2bca50ec-4076-4941-ab6b-7cccc83bc8d9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761720305.966347  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78761 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:61:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761720305.968009  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 78761 MB memory:  -> device: 1, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:62:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761720305.969526  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 78761 MB memory:  -> device: 2, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:63:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761720305.971003  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 78761 MB memory:  -> device: 3, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:64:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761720305.972473  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 78761 MB memory:  -> device: 4, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6a:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761720305.974493  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 78761 MB memory:  -> device: 5, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6b:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761720305.975964  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 78761 MB memory:  -> device: 6, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6c:00.0, compute capability: 9.0\n",
      "I0000 00:00:1761720305.977399  102393 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 78761 MB memory:  -> device: 7, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:6d:00.0, compute capability: 9.0\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_8', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_9', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_12', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_13', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_14', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'local_self_attention_15', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761720310.300208  103226 service.cc:152] XLA service 0x76d8d8002030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761720310.300240  103226 service.cc:160]   StreamExecutor device (0): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1761720310.300243  103226 service.cc:160]   StreamExecutor device (1): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1761720310.300245  103226 service.cc:160]   StreamExecutor device (2): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1761720310.300247  103226 service.cc:160]   StreamExecutor device (3): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1761720310.300248  103226 service.cc:160]   StreamExecutor device (4): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1761720310.300249  103226 service.cc:160]   StreamExecutor device (5): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1761720310.300262  103226 service.cc:160]   StreamExecutor device (6): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "I0000 00:00:1761720310.300265  103226 service.cc:160]   StreamExecutor device (7): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "2025-10-29 06:45:10.430885: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1761720311.160481  103226 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-10-29 06:45:15.316124: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 296 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:16.492077: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_31', 296 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:16.539525: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_27', 296 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:16.572362: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_62_0', 296 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:16.832869: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 528 bytes spill stores, 528 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:17.349223: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_70', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:17.549742: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_64', 340 bytes spill stores, 340 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:18.820428: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_64_0', 44 bytes spill stores, 44 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:19.797758: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 580 bytes spill stores, 596 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:20.037845: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_66', 1112 bytes spill stores, 888 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:20.355981: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_68', 112 bytes spill stores, 112 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:20.455758: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_70', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:20.937428: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_64', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:21.218392: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_68', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:21.638772: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_64', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:21.730748: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_63_0', 296 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2025-10-29 06:45:21.847656: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_32', 296 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "I0000 00:00:1761720330.978621  103226 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "import os, glob, math, random, sys\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "# ==============================================================================\n",
    "# Separation Constants\n",
    "# ==============================================================================\n",
    "\n",
    "TARGET_LEN = 441_000  # Model output length (10 seconds at 44.1kHz)\n",
    "SR = 44_100\n",
    "\n",
    "INSTRUMENT_NAMES = [\n",
    "    \"Guitar\", \"Drums\", \"Piano\", \"Bass\", \"Strings (continued)\",\n",
    "    \"Organ\", \"Synth Lead\", \"Synth Pad\", \"Chromatic Percussion\",\n",
    "    \"Brass\", \"Pipe\", \"Reed\", \"Strings\"\n",
    "]\n",
    "MODEL_KEYS = {f\"instrument_{i+1}\": name for i, name in enumerate(INSTRUMENT_NAMES)}\n",
    "\n",
    "# ==============================================================================\n",
    "# Utility Functions\n",
    "# ==============================================================================\n",
    "\n",
    "def pad_or_trim(x: np.ndarray, length: int) -> np.ndarray:\n",
    "    \"\"\"Zero-pad or trim audio to exactly `length` samples.\"\"\"\n",
    "    if len(x) >= length:\n",
    "        return x[:length]\n",
    "    pad = length - len(x)\n",
    "    left = pad // 2\n",
    "    right = pad - left\n",
    "    return np.pad(x, (left, right))\n",
    "\n",
    "\n",
    "def chunk_audio(wave: np.ndarray, chunk_size: int):\n",
    "    \"\"\"Yield non-overlapping chunks, zero-padding the last chunk if needed.\"\"\"\n",
    "    for start in range(0, len(wave), chunk_size):\n",
    "        end = min(start + chunk_size, len(wave))\n",
    "        chunk = wave[start:end]\n",
    "\n",
    "        if len(chunk) < chunk_size:\n",
    "            chunk = np.pad(chunk, (0, chunk_size - len(chunk)))\n",
    "\n",
    "        yield chunk\n",
    "\n",
    "\n",
    "def model_chunk_len(model):\n",
    "    \"\"\"Get the expected input length from model architecture.\"\"\"\n",
    "    tdim = model.input_shape[1]\n",
    "    if tdim is None:\n",
    "        # Fallback: find layer with target_len attribute\n",
    "        tdim = next((getattr(l, \"target_len\", None) for l in model.layers\n",
    "                    if hasattr(l, \"target_len\") and getattr(l, \"target_len\")), 441024)\n",
    "    return int(tdim)\n",
    "\n",
    "\n",
    "\n",
    "def load_audio(path, sr=44100):\n",
    "    \"\"\"Load audio file, resample if needed, and convert to mono float32.\"\"\"\n",
    "    p = Path(path).expanduser().resolve()\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Audio file not found: {p}\")\n",
    "    wav, file_sr = sf.read(str(p), always_2d=False)\n",
    "    if file_sr != sr:\n",
    "        import librosa\n",
    "        wav = librosa.resample(wav, orig_sr=file_sr, target_sr=sr)\n",
    "    if wav.ndim == 2:\n",
    "        wav = wav.mean(axis=1)  # Convert stereo to mono\n",
    "    return wav.astype(np.float32)\n",
    "\n",
    "\n",
    "def separate_long_audio(model, audio_path, output_dir, sr=44100):\n",
    "    \"\"\"\n",
    "    Separate a full-length audio file into instrument stems.\n",
    "    \n",
    "    Uses overlap-add processing for seamless output on long audio files.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        audio_path: Path to input audio file\n",
    "        output_dir: Directory to save separated stems\n",
    "        sr: Sample rate (default: 44100)\n",
    "    \"\"\"\n",
    "    # Load and prepare audio\n",
    "    audio_path = Path(audio_path).expanduser().resolve()\n",
    "    output_dir = Path(output_dir).expanduser().resolve()\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    wav, file_sr = sf.read(str(audio_path), always_2d=False)\n",
    "    if file_sr != sr:\n",
    "        import librosa\n",
    "        wav = librosa.resample(wav, orig_sr=file_sr, target_sr=sr)\n",
    "    if wav.ndim == 2:\n",
    "        wav = wav.mean(axis=1)\n",
    "    wav = wav.astype(np.float32)\n",
    "    global_peak = np.max(np.abs(wav)) + 1e-7\n",
    "\n",
    "    # Processing parameters\n",
    "    CHUNK = model_chunk_len(model)\n",
    "    HOP = TARGET_LEN // 2  # 50% overlap\n",
    "    WIN = np.sqrt(np.hanning(TARGET_LEN).astype(np.float32))\n",
    "    OFFSET = (CHUNK - TARGET_LEN) // 2\n",
    "\n",
    "    # Prepare overlap-add buffers for each instrument\n",
    "    keys = list(MODEL_KEYS.keys())\n",
    "    N = len(wav)\n",
    "    acc = {k: np.zeros(N + CHUNK, np.float32) for k in keys}\n",
    "    wsum = np.zeros(N + CHUNK, np.float32)\n",
    "\n",
    "    def predict_chunk(x):\n",
    "        \"\"\"Run model prediction on a single chunk and return stems dict.\"\"\"\n",
    "        x = x.astype(np.float32)\n",
    "        x_norm = x / global_peak  # Normalize to match training scale\n",
    "        if len(x_norm) < CHUNK:\n",
    "            x_norm = np.pad(x_norm, (0, CHUNK - len(x_norm)))\n",
    "        \n",
    "        outs = model.predict(x_norm[np.newaxis, :, np.newaxis], verbose=0)\n",
    "        \n",
    "        # Handle different output formats (list vs dict)\n",
    "        if isinstance(outs, list):\n",
    "            pred_dict = {k: v for k, v in zip(keys, outs)}\n",
    "        elif isinstance(outs, dict):\n",
    "            if keys and keys[0] in outs:\n",
    "                pred_dict = outs\n",
    "            else:\n",
    "                out_names = list(getattr(model, \"output_names\", []))\n",
    "                pred_dict = {k: outs[n] for k, n in zip(keys, out_names)} if out_names else {k: v for k, v in zip(keys, outs.values())}\n",
    "        else:\n",
    "            raise TypeError(\"Unsupported prediction return type\")\n",
    "        \n",
    "        return {k: pred_dict[k][0, :TARGET_LEN, 0] * global_peak for k in keys}\n",
    "\n",
    "    # Process audio with overlapping windows\n",
    "    for start in range(0, N, HOP):\n",
    "        end   = min(start + CHUNK, N)\n",
    "        chunk = wav[start:end]\n",
    "        pred  = predict_chunk(chunk)\n",
    "        w = WIN\n",
    "        if end - start < CHUNK:             # shorten window at tail if we didn’t pad\n",
    "            # we still padded for the net, so use full window; crop when adding\n",
    "            pass\n",
    "\n",
    "        for k in keys:\n",
    "            acc[k][start+OFFSET:start+OFFSET+TARGET_LEN] += pred[k] * WIN\n",
    "            wsum[start+OFFSET:start+OFFSET+TARGET_LEN] += WIN**2\n",
    "\n",
    "    # normalize by overlap weights and trim to original length\n",
    "    eps = 1e-8\n",
    "    out = {k: (acc[k][:N] / np.maximum(wsum[:N], eps)) for k in keys}\n",
    "\n",
    "    # save with human names\n",
    "    names = [\n",
    "        \"Guitar\",\"Drums\",\"Piano\",\"Bass\",\"Strings (continued)\",\n",
    "        \"Organ\",\"Synth Lead\",\"Synth Pad\",\"Chromatic Percussion\",\n",
    "        \"Brass\",\"Pipe\",\"Reed\",\"Strings\"\n",
    "    ]\n",
    "    key_to_name = {f\"instrument_{i+1}\": n for i, n in enumerate(names)}\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    for k, y in out.items():\n",
    "        sf.write(Path(output_dir, f\"{key_to_name.get(k,k)}.wav\"), y.astype(np.float32), sr, subtype=\"FLOAT\")\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Example Usage\n",
    "# ==============================================================================\n",
    "\n",
    "# Uncomment to run separation on a test file:\n",
    "# separate_long_audio(reloaded, \"~/path/to/input.wav\", \"~/path/to/output/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Cloud IDE)",
   "language": "python",
   "name": "cloud-ide"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
